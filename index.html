<!doctype html>
<meta charset="utf-8">
<style>
body {
  overflow-x: hidden;
}
#cover_sketch {padding: 0;
    margin: 0;
}
#cover_overlay_wrap {padding: 0;
    margin: 0;
    position: absolute;
    top: 0;
    left: 0;
}
#cover_overlay {padding: 0;
    margin: 0;
    position: absolute;
    top: 0;
    left: 0;
    background: #000000;
    opacity: 0.2;
    width: 100%;
    height: 100%;
}
#cover_title {padding: 0;
    margin: 0;
    position: absolute;
    top: 0;
    left: 0;
}
#cover_title_svg {padding: 0;
    margin: 0;
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
}
#loading_text {
  margin: 0;
  top: 0;
  left: 0;
  height: 100vh;
  width: 100vw;
}
.cover-instruction {
  width: 100%;
  height: 60px;
  bottom: 10%;
  position: absolute;
  font-family: "Roboto","Helvetica Neue",Helvetica,Arial,sans-serif;
  font-size: 16px;
  font-weight: 300;
  color: #FFFFFF;
}
.scroll-down {
  width: 80px;
  height: 40px;
  right: 10px;
  bottom: 10px;
  position: absolute;
  font-family: "Roboto","Helvetica Neue",Helvetica,Arial,sans-serif;
  font-size: 12px;
  font-weight: 300;
  color: #FFFFFF;
  opacity: 0;
  -webkit-transition: opacity 2s ease-in;
  -moz-transition: opacity 2s ease-in;
  -o-transition: opacity 2s ease-in;
  -ms-transition: opacity 2s ease-in;
  transition: opacity 2s ease-in;
}
.scroll-down span {
  margin-top: 5px;
  position: absolute;
  left: 50%;
  transform: translate(-100%, 0) rotate(45deg);
  transform-origin: 100% 100%;
  height: 2px;
  width: 10px;
  background: #FFFFFF;
}
.scroll-down span:nth-of-type(2) {
  transform-origin: 0 100%;
  transform: translate(0, 0) rotate(-45deg);
}
.spinner {
  position: absolute;
  height: 160px;
  width: 160px;
  -webkit-animation: rotation .6s infinite linear;
  -moz-animation: rotation .6s infinite linear;
  -o-animation: rotation .6s infinite linear;
  animation: rotation .6s infinite linear;
  border-left: 6px solid rgba(0, 174, 239, .15);
  border-right: 6px solid rgba(0, 174, 239, .15);
  border-bottom: 6px solid rgba(0, 174, 239, .15);
  border-top: 6px solid rgba(0, 174, 239, .8);
  border-radius: 100%;
  top: calc(50% - 100px);
  left: calc(50% - 80px);
  right: auto;
  bottom: auto;
}

@-webkit-keyframes rotation {
  from {
    -webkit-transform: rotate(0deg);
  }
  to {
    -webkit-transform: rotate(359deg);
  }
}
.transparent {
  opacity: 0;
}

.figload {
  font-family: Helvetica,Arial,sans-serif;
  font-weight: 400;
  color: rgba(0, 174, 239, .8);
  font-size: 24px;
  line-height: 1.5em;
  display: block;
  width: 100%;
  text-align: center;
  position: absolute;
  top: calc(50% - 80px + 190px);
}

dt-article figcaption {
  padding: 0.5em;
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
  text-align: left;
}

dt-article figcaption a {
  color: rgba(0, 0, 0, 0.6);
}

dt-article figcaption b {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

*.unselectable {
    -moz-user-select: -moz-none;
    -khtml-user-select: none;
    -webkit-user-select: none;
    -o-user-select: none;
    user-select: none;
}
*.svgunselectable {
    -moz-user-select: -moz-none;
    -khtml-user-select: none;
    -webkit-user-select: none;
    -o-user-select: none;
    user-select: none;
    background: none;
    pointer-events: none;
}
</style>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <!-- roboto font -->
  <link href='https://fonts.googleapis.com/css?family=Roboto:300' rel='stylesheet' type='text/css'>
  <!-- icons -->
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="logo/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-116311758-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-116311758-1');
  </script>
  <!-- SEO -->
  <meta property="og:title" content="World Models" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="Can agents learn inside of their own dreams?" />
  <meta property="og:image" content="https://worldmodels.github.io/assets/world_models_card_both.png" />
  <meta property="og:url" content="https://vkakerbeck.github.io/Learning-World-Representations/" />
  <!-- Twitter Card data -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="World Models" />
  <meta name="twitter:description" content="Can agents learn inside of their own dreams?" />
  <meta property="og:site_name" content="World Models" />
  <meta name="twitter:image" content="https://worldmodels.github.io/assets/world_models_card_single.png" />
    <!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
  <meta name="citation_title" content="World Models">
  <meta name="citation_doi" content="10.5281/zenodo.1207631">
  <meta name="citation_volume" content="1">
  <meta name="citation_issue" content="1">
  <meta name="citation_firstpage" content="e10">
  <meta name="citation_fulltext_world_readable" content="">
  <meta name="citation_fulltext_html_url" content="https://worldmodels.github.io/">
  <meta name="citation_online_date" content="2018/03/27">
  <meta name="citation_publication_date" content="2018/03/27">
  <meta name="citation_author" content="Ha, David">
  <meta name="citation_author_institution" content="Google Brain">
  <meta name="citation_author" content="Schmidhuber, Jürgen">
  <meta name="citation_author_institution" content="NNAISENSE">
  <meta name="citation_journal_title" content="World Models">
  <meta name="citation_journal_abbrev" content="World Models">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/1803.10122.pdf">
</head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">

<!-- used google storage instead: https://storage.googleapis.com/quickdraw-models/sketchRNN/world_models/ -->
<script src="https://storage.googleapis.com/quickdraw-models/sketchRNN/world_models/demo/lib/jquery-1.12.4.min.js"></script>
<script src="https://storage.googleapis.com/quickdraw-models/sketchRNN/world_models/demo/lib/mobile-detect.min.js"></script>
<script src="https://storage.googleapis.com/quickdraw-models/sketchRNN/world_models/demo/lib/template.v1.js"></script>

<!--
<script src="demo/lib/jquery-1.12.4.min.js"></script>
<script src="demo/lib/mobile-detect.min.js"></script>
<script src="demo/lib/template.v1.js"></script>
-->

<script src="demo/controller.js"></script>

<script type="text/front-matter">
  title: "World Models"
  description: "Can an agent to learn inside of its own dream?"
</script>
<body>
  <div id="loading_text">
  <div class="spinner"></div>
  <div class="figload">&nbsp;&nbsp;&nbsp;&nbsp;Loading World Models ...</div>
  </div>
<dt-article id="dtbody">
<div id="cover_sketch" class="unselectable" style="text-align: center;"></div>
<div id="cover_overlay_wrap" class="unselectable">
  <div id="cover_overlay" class="unselectable">
  </div>
  <div id="cover_instruction" class="cover-instruction" style="text-align: center;">
    <div id="cover_instruction_text">Interactive demo: Tap screen to override the agent's decisions.</div>
  </div>
  <div id="scrolldowntag" class="scroll-down" style="text-align: center;">
    <div>scroll down</div>
    <span></span>
    <span></span>
  </div>
</div>
<div id="cover_title" class="unselectable">
  <!--<img src="https://storage.googleapis.com/quickdraw-models/sketchRNN/world_models/assets/cover_title.svg" id="cover_title_svg" class="unselectable"/>-->
  <img src="assets/cover_title.svg" id="cover_title_svg" class="svgunselectable"/>
</div>
<!--<div><figcaption>An agent playing inside of a game environment hallucinated by a recurrent neural network.</figcaption></div>-->
<dt-byline class="l-page transparent"></dt-byline>
<div style="text-align: center;">
  <p>　</p>
</div>
<div style="text-align: center;">
  <p>　</p>
</div>
<h1>World Models</h1>
<p></p>
<h2>Can agents learn inside of their own dreams?</h2>
<dt-byline class="l-page" id="authors_section" hidden>
<div class="byline">
  <div class="authors">
    <div class="author">
        <a class="name" href="https://twitter.com/hardmaru">David Ha</a>
        <a class="affiliation" href="https://g.co/brain">Google Brain</a>
        <a class="affiliation" href="https://g.co/brain">Tokyo, Japan</a>
    </div>
    <div class="author">
        <a class="name" href="http://people.idsia.ch/~juergen/">Jürgen Schmidhuber</a>
        <a class="affiliation" href="https://nnaisense.com">NNAISENSE</a>
        <a class="affiliation" href="http://www.idsia.ch/">Swiss AI Lab, IDSIA (USI &amp; SUPSI)</a>
    </div>
  </div>
  <div class="date">
    <div class="month">March 27</div>
    <div class="year">2018</div>
    <div class="year">&nbsp;</div>
  </div>
  <div class="date">
    <div class="month"><a href="https://papers.nips.cc/paper/7512-recurrent-world-models-facilitate-policy-evolution" target="_blank">NIPS 2018</a></div>
    <div class="year" style="color: #668;"><a href="https://papers.nips.cc/paper/7512-recurrent-world-models-facilitate-policy-evolution" target="_blank">Paper</a></div>
    <div class="year">&nbsp;</div>
  </div>
  <div class="date">
    <div class="month"><a href="https://youtu.be/HzA8LRqhujk" target="_blank">YouTube</a></div>
    <div class="year" style="color: #668;"><a href="https://youtu.be/HzA8LRqhujk" target="_blank">Talk</a></div>
    <div class="year">&nbsp;</div>
  </div>
  <div class="date">
    <div class="month">Download</div>
    <div class="year" style="color: #FF6C00;"><a href="https://arxiv.org/abs/1803.10122" target="_blank">PDF</a></div>
    <div class="year">&nbsp;</div>
  </div>
</div>
</dt-byline><h2>Abstract</h2>
<p>We explore building generative neural network models of popular reinforcement learning environments. Our <em>world model</em> can be trained quickly in an unsupervised manner to learn a compressed spatial and temporal representation of the environment. By using features extracted from the world model as inputs to an agent, we can train a very compact and simple policy that can solve the required task. We can even train our agent entirely inside of its own dream environment generated by its world model, and transfer this policy back into the actual environment.</p>
<hr>
<h2>Introduction</h2>
<div style="text-align: left;">
<img src="assets/world_model_comic.jpeg" style="display: block; margin: auto; width: 100%;"/>
<figcaption>A World Model, from Scott McCloud's <i>Understanding Comics</i>. <dt-cite key="understandingcomics,understandingcomics_blog"></dt-cite></figcaption>
</div>
<p>Humans develop a mental model of the world based on what they are able to perceive with their limited senses. The decisions and actions we make are based on this internal model. Jay Wright Forrester, the father of system dynamics, described a mental model as:</p>
<p>“<em>The image of the world around us, which we carry in our head, is just a model. Nobody in his head imagines all the world, government or country. He has only selected concepts, and relationships between them, and uses those to represent the real system.</em>” <dt-cite key="forrester"></dt-cite></p>
<p>To handle the vast amount of information that flows through our daily lives, our brain learns an abstract representation of both spatial and temporal aspects of this information. We are able to observe a scene and remember an abstract description thereof <dt-cite key="facial_identity_primate_brain,single_neuron_viz"></dt-cite>. Evidence also suggests that what we perceive at any given moment is governed by our brain’s prediction of the future based on our internal model <dt-cite key="primary_viz_cortex_past_present,mt_motion"></dt-cite>.</p>
<div style="text-align: left;">
<img src="https://storage.googleapis.com/quickdraw-models/sketchRNN/world_models/assets/kitaoka.jpeg" style="display: block; margin: auto; width: 100%;"/>
<figcaption>What we see is based on our brain's prediction of the future. <dt-cite key="kitaoka,pdi,Watanabe2018"></dt-cite></figcaption>
</div>
<p>One way of understanding the predictive model inside of our brains is that it might not be about just predicting the future in general, but predicting future sensory data given our current motor actions <dt-cite key="Keller2012,Leinweber2017"></dt-cite>. We are able to instinctively act on this predictive model and perform fast reflexive behaviours when we face danger <dt-cite key="survival_optimization"></dt-cite>, without the need to consciously plan out a course of action.</p>
<p>Take baseball for example. A baseball batter has milliseconds to decide how they should swing the bat -- shorter than the time it takes for visual signals from our eyes to reach our brain. The reason we are able to hit a 100mph fastball is due to our ability to instinctively predict when and where the ball will go. For professional players, this all happens subconsciously. Their muscles reflexively swing the bat at the right time and location in line with their internal models' predictions <dt-cite key="mt_motion"></dt-cite>. They can quickly act on their predictions of the future without the need to consciously roll out possible future scenarios to form a plan <dt-cite key="mt_motion_article"></dt-cite>.</p>
<div style="text-align: center;">
<img src="assets/mccloud_baseball.jpeg" style="display: block; margin: auto; width: 100%;"/>
<figcaption>We learn to perceive time <i>spatially</i> when we read comics. According to cartoonist and comics theorist Scott McCloud, &ldquo;<i>in the world of comics, time and space are one and the same.</i>&rdquo; Art © Scott McCloud. <dt-cite key="understandingcomics"></dt-cite></figcaption>
</div>
<p>In many reinforcement learning (RL) problems <dt-cite key="Kaelbling:96,sutton_barto,wiering2012"></dt-cite>, an artificial agent also benefits from having a good representation of past and present states, and a good predictive model of the future <dt-cite key="Werbos87specifications,dyna_slides"></dt-cite>, preferably a powerful predictive model implemented on a general purpose computer such as a recurrent neural network (RNN) <dt-cite key="s05_making_the_world_differentiable,s05a_cm,s05b_rl"></dt-cite>.</p>
</dt-article>
